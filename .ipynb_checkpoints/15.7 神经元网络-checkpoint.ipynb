{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "RBF神经网络经过这样两层变化: $\\left\\{\\begin{array}{l}R_i(X)=exp(-||X-C_i||^2/2\\sigma_i^2),\\qquad i=1,\\cdots,m\\\\\\hat{y}_k=\\sum\\limits_{i=1}^{m}\\omega_{ik}R_i(X),\\qquad k=1,\\cdots,p\\end{array}\\right.$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "这样只有小部分靠近中心的隐藏层神经元被激活($R_i(X)$随着其中范数增大,指数减少)"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "确定基函数中心$C_i$. 一般采用K均值聚类法."
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "确定基函数宽度$\\sigma_i$. 通常令它等于基函数中心与子样本集中样本模式之间的平均距离"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "确定权值$\\omega_{ik}$. 采用最小均方误差测度."
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1.BP神经网络\n",
    "#   见 'MPLClassifier.ipynb'\n",
    "# 2.RBF神经网络\n",
    "from IPython.display import Latex\n",
    "from IPython.display import display, Math, Latex\n",
    "\n",
    "\n",
    "def print_latex(latex_str):\n",
    "    display(Latex(latex_str))\n",
    "    \n",
    "    \n",
    "print_latex(r'RBF神经网络经过这样两层变化: $\\left\\{\\begin{array}{l}R_i(X)=exp(-||X-C_i||^2/2\\sigma_i^2),\\qquad i=1,\\cdots,m\\\\\\hat{y}_k=\\sum\\limits_{i=1}^{m}\\omega_{ik}R_i(X),\\qquad k=1,\\cdots,p\\end{array}\\right.$')\n",
    "print_latex(r'这样只有小部分靠近中心的隐藏层神经元被激活($R_i(X)$随着其中范数增大,指数减少)')\n",
    "print_latex(r'确定基函数中心$C_i$. 一般采用K均值聚类法.')\n",
    "print_latex(r'确定基函数宽度$\\sigma_i$. 通常令它等于基函数中心与子样本集中样本模式之间的平均距离')\n",
    "print_latex(r'确定权值$\\omega_{ik}$. 采用最小均方误差测度.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function at step 0 is 6.022715091705322\n",
      "Loss function at step 20 is 0.7577824592590332\n",
      "Loss function at step 40 is 0.26232367753982544\n",
      "Loss function at step 60 is 0.2842783033847809\n",
      "Loss function at step 80 is 0.49424320459365845\n",
      "Loss function at step 100 is 0.12203948944807053\n",
      "Loss function at step 120 is 0.13805973529815674\n",
      "Loss function at step 140 is 0.026434509083628654\n",
      "Loss function at step 160 is 0.16529932618141174\n",
      "Loss function at step 180 is 0.11005460470914841\n",
      "Training complete!\n",
      "Relative Error Sum: 2450.0045%\n",
      "                                                Input Pred Out Raw Out  \\\n",
      "0   [-0.76797444 -0.13832668 -0.38830596  1.31866573]  -0.6608    -0.2   \n",
      "1   [ 0.02401949 -0.32662479 -0.67466729 -0.59120002]   0.3709    -0.1   \n",
      "2   [ 0.50440925 -0.51492289  3.57493482 -1.02038333]   0.8837     1.9   \n",
      "3   [-1.11852913 -0.45698501 -0.38830596 -0.62338876]   0.3612    -0.3   \n",
      "4   [ 0.10841228  3.85938689 -0.60594057  1.15772199]   1.7580    -2.6   \n",
      "5   [-1.11852913  0.73074149 -0.53721385  1.44742073]  -0.3525     0.8   \n",
      "6   [ 0.51739275 -0.35559373 -0.64030393 -0.6663071 ]   0.7285     0.3   \n",
      "7   [-1.21590543 -0.44250054  0.06987216 -0.88089875]   0.6663    -0.5   \n",
      "8   [-0.1317826  -0.84806569  1.75367678  2.38089444]   0.9337     0.4   \n",
      "9   [-0.7874497  -0.08038881 -0.56012276  0.4602991 ]   0.1996     2.0   \n",
      "10  [-0.09932383 -0.77564334  0.24168896 -1.06330166]  -0.0245    -0.2   \n",
      "11  [ 2.39350951 -0.4135316  -0.26230698 -0.90235792]  -0.4242    -0.6   \n",
      "12  [ 1.84820222 -0.52940736 -0.75484846 -0.85943959]  -0.2896    -0.6   \n",
      "13  [-0.5083043   0.57141232  0.43641466 -0.31223086]   0.6273     0.7   \n",
      "14  [ 0.53037626 -0.60182971 -0.03321791  1.22209949]  -0.0823    -0.2   \n",
      "15  [-1.07308685  0.41208316 -0.6975762  -0.65557751]  -0.8079    -0.8   \n",
      "16  [-0.17722487  0.23826952  0.09278107  0.12768204]  -0.0488    -0.0   \n",
      "17  [-0.31355169  0.67280361  0.34477904  0.56759493]  -0.8870    -1.0   \n",
      "18  [-0.38496098 -0.52940736 -0.60594057 -0.93454667]  -0.2825    -0.3   \n",
      "19  [ 1.77030118 -0.47146948 -0.36539706 -0.17274628]   0.9229     1.3   \n",
      "\n",
      "      Error Relative Error  \n",
      "0   -0.5043      322.2659%  \n",
      "1    0.4539     -546.7572%  \n",
      "2   -1.0022      -53.1415%  \n",
      "3    0.6499     -225.1087%  \n",
      "4    4.3387     -168.1169%  \n",
      "5   -1.1511     -144.1463%  \n",
      "6    0.4002      121.8542%  \n",
      "7    1.1166     -247.9546%  \n",
      "8    0.5612      150.6730%  \n",
      "9   -1.7597      -89.8125%  \n",
      "10   0.1467      -85.6748%  \n",
      "11   0.1877      -30.6787%  \n",
      "12   0.3517      -54.8403%  \n",
      "13  -0.0390       -5.8569%  \n",
      "14   0.0888      -51.8963%  \n",
      "15   0.0391       -4.6210%  \n",
      "16  -0.0246      101.3815%  \n",
      "17   0.0923       -9.4265%  \n",
      "18   0.0209       -6.8900%  \n",
      "19  -0.3753      -28.9078%  \n"
     ]
    }
   ],
   "source": [
    "# RBF神经网络(based on tensorflow): https://github.com/shiluqiang/RBF_NN_tensorflow/blob/master/RBF_tensorflow.py\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "def load_data(file_name):\n",
    "    '''导入数据\n",
    "    input:  file_name(string):文件的存储位置\n",
    "    output: feature_data(mat):特征\n",
    "            label_data(mat):标签\n",
    "            n_class(int):类别的个数\n",
    "    '''\n",
    "    # 1、获取特征\n",
    "    f = open(file_name)  # 打开文件\n",
    "    feature_data = []\n",
    "    label_tmp = []\n",
    "    for line in f.readlines():\n",
    "        feature_tmp = []\n",
    "        lines = line.strip().split(\"\\t\")\n",
    "        for i in range(len(lines) - 1):\n",
    "            feature_tmp.append(float(lines[i]))\n",
    "        label_tmp.append(int(lines[-1]))      \n",
    "        feature_data.append(feature_tmp)\n",
    "    f.close()  # 关闭文件\n",
    "    \n",
    "    # 2、获取标签\n",
    "    m = len(label_tmp)\n",
    "    n_class = len(set(label_tmp))  # 得到类别的个数\n",
    "    \n",
    "    label_data = np.mat(np.zeros((m, n_class)))\n",
    "    for i in range(m):\n",
    "        label_data[i, label_tmp[i]] = 1\n",
    "    \n",
    "    return np.mat(feature_data), label_data\n",
    "\n",
    "class RBF_NN():\n",
    "    def __init__(self, hidden_nodes, input_data_trainX, input_data_trainY):\n",
    "        self.hidden_nodes = hidden_nodes #隐含层节点数\n",
    "        self.input_data_trainX = input_data_trainX #训练样本的特征\n",
    "        self.input_data_trainY = input_data_trainY #训练样本的标签\n",
    "    \n",
    "    def fit(self):\n",
    "        '''模型训练\n",
    "        '''\n",
    "        # 1.声明输入输出的占位符\n",
    "        n = 10\n",
    "        n_input = (self.input_data_trainX).shape[1]\n",
    "        n_output = (self.input_data_trainY).shape[0]\n",
    "        X = tf.placeholder('float', [None, n_input],name = 'X')\n",
    "        Y = tf.placeholder('float', [None, 1],name = 'Y')\n",
    "        \n",
    "        # 2.参数设置\n",
    "        ## RBF函数参数\n",
    "        ### K-means求中心\n",
    "        random_state = 170\n",
    "        kms = KMeans(n_clusters=self.hidden_nodes, random_state=None)\n",
    "        pred = kms.fit_predict(trainX)\n",
    "        \n",
    "        # c = tf.Variable(tf.random_normal(shape=(self.hidden_nodes, n_input)),name = 'c')\n",
    "        # c = tf.concat((tf.cast(tf.Variable(kms.cluster_centers_), tf.float32), c), axis=0)\n",
    "        c = tf.cast(tf.Variable(kms.cluster_centers_), tf.float32)\n",
    "        delta = tf.Variable(tf.random_normal(shape=(1,self.hidden_nodes)), name='delta')\n",
    "        ## 隐含层到输出层权重和偏置\n",
    "        W = tf.Variable(tf.random_normal(shape=(self.hidden_nodes, 1)), name='W')\n",
    "        b = tf.Variable(tf.random_normal(shape=(1, 1)), name='b')\n",
    "        \n",
    "        # 3.构造前向传播计算图\n",
    "        ## 隐含层输出\n",
    "        ### 特征样本与RBF均值的距离\n",
    "        dist = tf.reduce_sum(tf.square(tf.subtract(tf.tile(X,[self.hidden_nodes, 1]),c)), axis=1)\n",
    "        dist = tf.multiply(1.0,tf.transpose(dist))\n",
    "        ### RBF方差的平方\n",
    "        delta_2 = tf.square(delta)\n",
    "        ### 隐含层输出\n",
    "        RBF_OUT = tf.exp(tf.multiply(-1.0,tf.divide(dist,tf.multiply(2.0,delta_2))))\n",
    "        ## 输出层输入\n",
    "        output_in = tf.matmul(RBF_OUT, W) + b\n",
    "        \n",
    "        # 4.声明代价函数优化算法\n",
    "        loss = tf.reduce_mean(tf.pow(Y - output_in,2)) #损失函数为均方误差\n",
    "        train_op = tf.train.AdamOptimizer(0.05).minimize(loss) #优化算法为梯度下降法\n",
    "        \n",
    "        # 5.反向传播求参数\n",
    "        trX = self.input_data_trainX[n:]\n",
    "        trY = self.input_data_trainY[n:]\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            ## 初始化所有参数\n",
    "            tf.global_variables_initializer().run()\n",
    "            for epoch in range(200):\n",
    "                for i in range(trX.shape[0]):\n",
    "                    feed = {X:trX[i][:,None].T, Y:[[trY[i]]]}\n",
    "                    sess.run(train_op,feed_dict=feed)\n",
    "                if epoch % 20. == 0 :\n",
    "                    total_loss = 0.0\n",
    "                    for j in range(trX.shape[0]):\n",
    "                        total_loss += sess.run(loss, feed_dict={X:trX[i][:,None].T, Y:[[trY[i]]]})\n",
    "                    print('Loss function at step %d is %s'%(epoch, total_loss / trX.shape[0]))\n",
    "                    \n",
    "            print('Training complete!')\n",
    "\n",
    "            W = W.eval()\n",
    "            b = b.eval()\n",
    "            c = c.eval()\n",
    "            delta = delta.eval()\n",
    "            pred_trX = np.mat(np.zeros((len(trX),n_output)))\n",
    "            \n",
    "            ## 训练准确率\n",
    "            correct_tr = 0.0\n",
    "            pred = []\n",
    "            for i in range(self.input_data_trainX.shape[0]):\n",
    "                pred_tr = sess.run(output_in, feed_dict={X:self.input_data_trainX[i][:,None].T})\n",
    "                pred.append(pred_tr[0][0])\n",
    "            df_columns = ['Input', 'Pred Out', 'Raw Out', 'Error', 'Relative Error']\n",
    "            pred = np.array(pred)\n",
    "            df = pd.DataFrame(np.c_[[x.__str__() for x in self.input_data_trainX],\n",
    "                                    pred,\n",
    "                                    self.input_data_trainY,\n",
    "                                    np.subtract(pred, self.input_data_trainY),\n",
    "                                    np.array(np.divide(np.subtract(pred, self.input_data_trainY), self.input_data_trainY), dtype=np.float)\n",
    "                                   ], columns=df_columns)\n",
    "            print('Relative Error Sum: {:.4%}'.format(df['Relative Error'].astype(float).abs().sum()))\n",
    "            df['Pred Out'] = df['Pred Out'].apply(lambda x: format(float(x), '.4f'))\n",
    "            df['Raw Out'] = df['Raw Out'].apply(lambda x: format(float(x), '.1f'))\n",
    "            df['Error'] = df['Error'].apply(lambda x: format(float(x), '.4f'))\n",
    "            df['Relative Error'] = df['Relative Error'].apply(lambda x: format(float(x), '.4%'))\n",
    "            print(df)\n",
    "            # self.save_model('RBF_predict_results.txt',pred_trX)\n",
    "            \n",
    "    def save_model(self,file_name,weights):\n",
    "        '''保存模型(保存权重weights)\n",
    "        input：file_name(string):文件名\n",
    "               weights(mat)：权重矩阵\n",
    "        '''\n",
    "        f_w = open(file_name,'w')\n",
    "        m,n = np.shape(weights)\n",
    "        for i in range(m):\n",
    "            w_tmp = []\n",
    "            for j in range(n):\n",
    "                w_tmp.append(str(weights[i,j]))\n",
    "            f_w.write('\\t'.join(w_tmp)+'\\n')\n",
    "        f_w.close()\n",
    "            \n",
    "\n",
    "data = np.loadtxt('15.D 水库年径流与因子特征.txt')\n",
    "data = preprocessing.scale(data)\n",
    "\n",
    "trainX = data[:, :-1]\n",
    "trainY = data[:, -1]\n",
    "input_data_trainX = trainX\n",
    "input_data_trainY = trainY\n",
    "rbf = RBF_NN(10, input_data_trainX, input_data_trainY)\n",
    "rbf.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative Error Sum: 1106.5339%\n",
      "                    Input Pred Out Raw Out     Error Relative Error\n",
      "0   [15.6  5.6  3.5 25.5]  24.7561    22.9    1.8561        8.1053%\n",
      "1   [27.8  4.3  1.   7.7]  16.0371    23.4   -7.3629      -31.4655%\n",
      "2   [35.2  3.  38.1  3.7]  31.9578    36.8   -4.8422      -13.1582%\n",
      "3   [10.2  3.4  3.5  7.4]  10.8837    22.0  -11.1163      -50.5288%\n",
      "4   [29.1 33.2  1.6 24. ]  39.7648     6.4   33.3648      521.3253%\n",
      "5   [10.2 11.6  2.2 26.7]  26.1132    29.4   -3.2869      -11.1798%\n",
      "6   [35.4  4.1  1.3  7. ]  18.0605    26.2   -8.1395      -31.0668%\n",
      "7       [8.7 3.5 7.5 5. ]  10.4941    20.9  -10.4059      -49.7892%\n",
      "8   [25.4  0.7 22.2 35.4]  39.6342    26.5   13.1342       49.5631%\n",
      "9   [15.3  6.   2.  17.5]  18.9886    37.3  -18.3114      -49.0921%\n",
      "10  [25.9  1.2  9.   3.3]  15.2655    22.8   -7.5345      -33.0462%\n",
      "11  [64.3  3.7  4.6  4.8]  26.3268    19.8    6.5268       32.9635%\n",
      "12  [55.9  2.9  0.3  5.2]  22.0821    19.6    2.4821       12.6638%\n",
      "13  [19.6 10.5 10.7 10.3]  20.8392    28.5   -7.6608      -26.8800%\n",
      "14  [35.6  2.4  6.6 24.6]  31.5909    22.8    8.7909       38.5568%\n",
      "15  [10.9  9.4  0.8  7.1]  12.3786    18.2   -5.8214      -31.9855%\n",
      "16  [24.7  8.2  7.7 14.4]  23.6095    23.8   -0.1905       -0.8003%\n",
      "17  [22.6 11.2  9.9 18.5]  26.6116    17.3    9.3116       53.8240%\n",
      "18  [21.5  2.9  1.6  4.5]  11.8166    21.9  -10.0834      -46.0431%\n",
      "19  [54.7  3.3  3.7 11.6]  28.0451    32.8   -4.7549      -14.4967%\n"
     ]
    }
   ],
   "source": [
    "# BP神经网络(based on keras)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "\n",
    "data = np.loadtxt('15.D 水库年径流与因子特征.txt')\n",
    "X = data[:, :-1]\n",
    "Y = data[:, -1]\n",
    "n = 5\n",
    "trainX = X[n:]\n",
    "trainY = Y[n:]\n",
    "\n",
    "model = Sequential()  #层次模型\n",
    "model.add(Dense(12, input_dim=4)) #输入层，Dense表示BP层\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(5, input_dim=12))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1, input_dim=5))  #输出层\n",
    "model.compile(loss='mean_squared_error', optimizer='Adam') #编译模型\n",
    "model.fit(trainX, trainY, epochs = 100, batch_size = 10, verbose=0) #训练模型1000次\n",
    "\n",
    "pred = np.array(model.predict(X)).flatten()\n",
    "df_columns = ['Input', 'Pred Out', 'Raw Out', 'Error', 'Relative Error']\n",
    "df = pd.DataFrame(np.c_[[x.__str__() for x in X],\n",
    "                    pred,\n",
    "                    Y,\n",
    "                    np.subtract(pred, Y),\n",
    "                    np.array(np.divide(np.subtract(pred, Y), Y), dtype=np.float)\n",
    "                   ], columns=df_columns)\n",
    "print('Relative Error Sum: {:.4%}'.format(df['Relative Error'].astype(float).abs().sum()))\n",
    "df['Pred Out'] = df['Pred Out'].apply(lambda x: format(float(x), '.4f'))\n",
    "df['Raw Out'] = df['Raw Out'].apply(lambda x: format(float(x), '.1f'))\n",
    "df['Error'] = df['Error'].apply(lambda x: format(float(x), '.4f'))\n",
    "df['Relative Error'] = df['Relative Error'].apply(lambda x: format(float(x), '.4%'))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n",
      "2.2.4-tf\n",
      "['D:\\\\Jupyter_file\\\\Mathematical_Modeling_in_Python',\n",
      " 'D:\\\\Anaconda3\\\\python37.zip',\n",
      " 'D:\\\\Anaconda3\\\\DLLs',\n",
      " 'D:\\\\Anaconda3\\\\lib',\n",
      " 'D:\\\\Anaconda3',\n",
      " '',\n",
      " 'D:\\\\Anaconda3\\\\lib\\\\site-packages',\n",
      " 'D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32',\n",
      " 'D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
      " 'D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\Pythonwin',\n",
      " 'D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\extensions',\n",
      " 'C:\\\\Users\\\\89565\\\\.ipython']\n",
      "2.1.3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow import keras\n",
    "print(keras.__version__)\n",
    "import sys\n",
    "import pprint\n",
    "pprint.pprint(sys.path)\n",
    "import keras\n",
    "print(keras.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
