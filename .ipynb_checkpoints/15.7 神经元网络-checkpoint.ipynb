{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "RBF神经网络经过这样两层变化: $\\left\\{\\begin{array}{l}R_i(X)=exp(-||X-C_i||^2/2\\sigma_i^2),\\qquad i=1,\\cdots,m\\\\\\hat{y}_k=\\sum\\limits_{i=1}^{m}\\omega_{ik}R_i(X),\\qquad k=1,\\cdots,p\\end{array}\\right.$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "这样只有小部分靠近中心的隐藏层神经元被激活($R_i(X)$随着其中范数增大,指数减少)"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "确定基函数中心$C_i$. 一般采用K均值聚类法."
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "确定基函数宽度$\\sigma_i$. 通常令它等于基函数中心与子样本集中样本模式之间的平均距离"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "确定权值$\\omega_{ik}$. 采用最小均方误差测度."
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1.BP神经网络\n",
    "#   见 'MPLClassifier.ipynb'\n",
    "# 2.RBF神经网络\n",
    "from IPython.display import Latex\n",
    "from IPython.display import display, Math, Latex\n",
    "\n",
    "\n",
    "def print_latex(latex_str):\n",
    "    display(Latex(latex_str))\n",
    "    \n",
    "    \n",
    "print_latex(r'RBF神经网络经过这样两层变化: $\\left\\{\\begin{array}{l}R_i(X)=exp(-||X-C_i||^2/2\\sigma_i^2),\\qquad i=1,\\cdots,m\\\\\\hat{y}_k=\\sum\\limits_{i=1}^{m}\\omega_{ik}R_i(X),\\qquad k=1,\\cdots,p\\end{array}\\right.$')\n",
    "print_latex(r'这样只有小部分靠近中心的隐藏层神经元被激活($R_i(X)$随着其中范数增大,指数减少)')\n",
    "print_latex(r'确定基函数中心$C_i$. 一般采用K均值聚类法.')\n",
    "print_latex(r'确定基函数宽度$\\sigma_i$. 通常令它等于基函数中心与子样本集中样本模式之间的平均距离')\n",
    "print_latex(r'确定权值$\\omega_{ik}$. 采用最小均方误差测度.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-eb6efa5633ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# 由于数据量小,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# RBF神经网络(based on tensorflow): https://github.com/shiluqiang/RBF_NN_tensorflow/blob/master/RBF_tensorflow.py\n",
    "# 由于数据量小, 本人的不熟悉等原因, 预测结果并不理想.\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "class RBF_NN():\n",
    "    def __init__(self, hidden_nodes, input_data_trainX, input_data_trainY):\n",
    "        self.hidden_nodes = hidden_nodes #隐含层节点数\n",
    "        self.input_data_trainX = input_data_trainX #训练样本的特征\n",
    "        self.input_data_trainY = input_data_trainY #训练样本的标签\n",
    "    \n",
    "    def fit(self):\n",
    "        '''模型训练\n",
    "        '''\n",
    "        # 1.声明输入输出的占位符\n",
    "        n = 19\n",
    "        n_input = (self.input_data_trainX).shape[1]\n",
    "        n_output = (self.input_data_trainY).shape[0]\n",
    "        X = tf.placeholder('float', [None, n_input],name = 'X')\n",
    "        Y = tf.placeholder('float', [None, 1],name = 'Y')\n",
    "        \n",
    "        # 2.参数设置\n",
    "        ## RBF函数参数\n",
    "        ### K-means求中心\n",
    "        random_state = 170\n",
    "        kms = KMeans(n_clusters=self.hidden_nodes, random_state=None)\n",
    "        pred = kms.fit_predict(trainX)\n",
    "        \n",
    "        # c = tf.Variable(tf.random_normal(shape=(self.hidden_nodes, n_input)),name = 'c')\n",
    "        # c = tf.concat((tf.cast(tf.Variable(kms.cluster_centers_), tf.float32), c), axis=0)\n",
    "        c = tf.cast(tf.Variable(kms.cluster_centers_), tf.float32)\n",
    "        delta = tf.Variable(tf.random_normal(shape=(1,self.hidden_nodes)), name='delta')\n",
    "        ## 隐含层到输出层权重和偏置\n",
    "        W = tf.Variable(tf.random_normal(shape=(self.hidden_nodes, 1)), name='W')\n",
    "        b = tf.Variable(tf.random_normal(shape=(1, 1)), name='b')\n",
    "        \n",
    "        # 3.构造前向传播计算图\n",
    "        ## 隐含层输出\n",
    "        ### 特征样本与RBF均值的距离\n",
    "        dist = tf.reduce_sum(tf.square(tf.subtract(tf.tile(X,[self.hidden_nodes, 1]),c)), axis=1)\n",
    "        dist = tf.multiply(1.0,tf.transpose(dist))\n",
    "        ### RBF方差的平方\n",
    "        delta_2 = tf.square(delta)\n",
    "        ### 隐含层输出\n",
    "        RBF_OUT = tf.exp(tf.multiply(-1.0,tf.divide(dist,tf.multiply(2.0,delta_2))))\n",
    "        ## 输出层输入\n",
    "        output_in = tf.matmul(RBF_OUT, W) + b\n",
    "        \n",
    "        # 4.声明代价函数优化算法\n",
    "        loss = tf.reduce_mean(tf.pow(Y - output_in,2)) #损失函数为均方误差\n",
    "        train_op = tf.train.AdamOptimizer(0.05).minimize(loss) #优化算法为梯度下降法\n",
    "        \n",
    "        # 5.反向传播求参数\n",
    "        trX = self.input_data_trainX[:n]\n",
    "        trY = self.input_data_trainY[:n]\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            ## 初始化所有参数\n",
    "            tf.global_variables_initializer().run()\n",
    "            for epoch in range(200):\n",
    "                for i in range(trX.shape[0]):\n",
    "                    feed = {X:trX[i][:,None].T, Y:[[trY[i]]]}\n",
    "                    sess.run(train_op,feed_dict=feed)\n",
    "                if epoch % 20. == 0 :\n",
    "                    total_loss = 0.0\n",
    "                    for j in range(trX.shape[0]):\n",
    "                        total_loss += sess.run(loss, feed_dict={X:trX[i][:,None].T, Y:[[trY[i]]]})\n",
    "                    print('Loss function at step %d is %s'%(epoch, total_loss / trX.shape[0]))\n",
    "                    \n",
    "            print('Training complete!')\n",
    "\n",
    "            W = W.eval()\n",
    "            b = b.eval()\n",
    "            c = c.eval()\n",
    "            delta = delta.eval()\n",
    "            pred_trX = np.mat(np.zeros((len(trX),n_output)))\n",
    "            \n",
    "            ## 训练准确率\n",
    "            correct_tr = 0.0\n",
    "            pred = []\n",
    "            for i in range(self.input_data_trainX.shape[0]):\n",
    "                pred_tr = sess.run(output_in, feed_dict={X:self.input_data_trainX[i][:,None].T})\n",
    "                pred.append(pred_tr[0][0])\n",
    "            df_columns = ['Input', 'Pred Out', 'Raw Out', 'Error', 'Relative Error']\n",
    "            pred = np.array(pred)\n",
    "            df = pd.DataFrame(np.c_[[x.__str__() for x in self.input_data_trainX],\n",
    "                                    pred,\n",
    "                                    self.input_data_trainY,\n",
    "                                    np.subtract(pred, self.input_data_trainY),\n",
    "                                    np.array(np.divide(np.subtract(pred, self.input_data_trainY), self.input_data_trainY), dtype=np.float)\n",
    "                                   ], columns=df_columns)\n",
    "            print('Relative Error Sum: {:.4%}'.format(df['Relative Error'].astype(float).abs().sum()))\n",
    "            df['Pred Out'] = df['Pred Out'].apply(lambda x: format(float(x), '.4f'))\n",
    "            df['Raw Out'] = df['Raw Out'].apply(lambda x: format(float(x), '.1f'))\n",
    "            df['Error'] = df['Error'].apply(lambda x: format(float(x), '.4f'))\n",
    "            df['Relative Error'] = df['Relative Error'].apply(lambda x: format(float(x), '.4%'))\n",
    "            print(df)\n",
    "            # self.save_model('RBF_predict_results.txt',pred_trX)\n",
    "            \n",
    "    def save_model(self,file_name,weights):\n",
    "        '''保存模型(保存权重weights)\n",
    "        input：file_name(string):文件名\n",
    "               weights(mat)：权重矩阵\n",
    "        '''\n",
    "        f_w = open(file_name,'w')\n",
    "        m,n = np.shape(weights)\n",
    "        for i in range(m):\n",
    "            w_tmp = []\n",
    "            for j in range(n):\n",
    "                w_tmp.append(str(weights[i,j]))\n",
    "            f_w.write('\\t'.join(w_tmp)+'\\n')\n",
    "        f_w.close()\n",
    "            \n",
    "\n",
    "data = np.loadtxt('15.D 水库年径流与因子特征.txt')\n",
    "data = preprocessing.scale(data)\n",
    "\n",
    "trainX = data[:, :-1]\n",
    "trainY = data[:, -1]\n",
    "input_data_trainX = trainX\n",
    "input_data_trainY = trainY\n",
    "rbf = RBF_NN(10, input_data_trainX, input_data_trainY)\n",
    "rbf.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At the end of epoch: 0, with loss: 921.4054565429688\n",
      "At the end of epoch: 200, with loss: 57.29780197143555\n",
      "At the end of epoch: 400, with loss: 45.08501116434733\n",
      "At the end of epoch: 600, with loss: 34.48600959777832\n",
      "At the end of epoch: 800, with loss: 24.012651761372883\n",
      "Relative Error Sum: 928.5028%\n",
      "                    Input Pred Out Raw Out    Error Relative Error\n",
      "0   [15.6  5.6  3.5 25.5]  32.5505    22.9   9.6505       42.1419%\n",
      "1   [27.8  4.3  1.   7.7]  22.2071    23.4  -1.1929       -5.0979%\n",
      "2   [35.2  3.  38.1  3.7]  41.1654    36.8   4.3654       11.8625%\n",
      "3   [10.2  3.4  3.5  7.4]  13.3210    22.0  -8.6790      -39.4500%\n",
      "4   [29.1 33.2  1.6 24. ]  47.9056     6.4  41.5056      648.5251%\n",
      "5   [10.2 11.6  2.2 26.7]  29.9794    29.4   0.5794        1.9707%\n",
      "6   [35.4  4.1  1.3  7. ]  25.4290    26.2  -0.7710       -2.9428%\n",
      "7       [8.7 3.5 7.5 5. ]  14.4933    20.9  -6.4067      -30.6539%\n",
      "8   [25.4  0.7 22.2 35.4]  25.4681    26.5  -1.0319       -3.8939%\n",
      "9   [15.3  6.   2.  17.5]  30.7339    37.3  -6.5661      -17.6034%\n",
      "10  [25.9  1.2  9.   3.3]  21.7415    22.8  -1.0585       -4.6425%\n",
      "11  [64.3  3.7  4.6  4.8]  21.1400    19.8   1.3400        6.7678%\n",
      "12  [55.9  2.9  0.3  5.2]  18.0876    19.6  -1.5124       -7.7163%\n",
      "13  [19.6 10.5 10.7 10.3]  24.7933    28.5  -3.7067      -13.0058%\n",
      "14  [35.6  2.4  6.6 24.6]  25.5979    22.8   2.7979       12.2715%\n",
      "15  [10.9  9.4  0.8  7.1]  18.8512    18.2   0.6512        3.5778%\n",
      "16  [24.7  8.2  7.7 14.4]  25.4267    23.8   1.6267        6.8349%\n",
      "17  [22.6 11.2  9.9 18.5]  26.2508    17.3   8.9508       51.7387%\n",
      "18  [21.5  2.9  1.6  4.5]  18.4836    21.9  -3.4164      -15.5998%\n",
      "19  [54.7  3.3  3.7 11.6]  33.5235    32.8   0.7235        2.2057%\n"
     ]
    }
   ],
   "source": [
    "# BP神经网络(based on keras)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "\n",
    "data = np.loadtxt('15.D 水库年径流与因子特征.txt')\n",
    "X = data[:, :-1]\n",
    "Y = data[:, -1]\n",
    "n = 5\n",
    "trainX = X[n:]\n",
    "trainY = Y[n:]\n",
    "\n",
    "model = Sequential()  #层次模型\n",
    "model.add(Dense(12, input_dim=4)) #输入层，Dense表示BP层\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(5, input_dim=12))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1, input_dim=5))  #输出层\n",
    "model.compile(loss='mean_squared_error', optimizer='Adam') #编译模型\n",
    "\n",
    "\n",
    "def eposh_callback(epoch, logs):\n",
    "    if epoch % 200 == 0:\n",
    "        print('At the end of epoch: {}, with loss: {}'.format(epoch, logs['loss']))\n",
    "        \n",
    "        \n",
    "batch_print_callback = keras.callbacks.LambdaCallback(on_epoch_end=eposh_callback)\n",
    "model.fit(trainX, trainY, epochs = 1000, batch_size = 5, verbose=0, callbacks=[batch_print_callback]) #训练模型1000次\n",
    "\n",
    "pred = np.array(model.predict(X)).flatten()\n",
    "df_columns = ['Input', 'Pred Out', 'Raw Out', 'Error', 'Relative Error']\n",
    "df = pd.DataFrame(np.c_[[x.__str__() for x in X],\n",
    "                    pred,\n",
    "                    Y,\n",
    "                    np.subtract(pred, Y),\n",
    "                    np.array(np.divide(np.subtract(pred, Y), Y), dtype=np.float)\n",
    "                   ], columns=df_columns)\n",
    "print('Relative Error Sum: {:.4%}'.format(df['Relative Error'].astype(float).abs().sum()))\n",
    "df['Pred Out'] = df['Pred Out'].apply(lambda x: format(float(x), '.4f'))\n",
    "df['Raw Out'] = df['Raw Out'].apply(lambda x: format(float(x), '.1f'))\n",
    "df['Error'] = df['Error'].apply(lambda x: format(float(x), '.4f'))\n",
    "df['Relative Error'] = df['Relative Error'].apply(lambda x: format(float(x), '.4%'))\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
